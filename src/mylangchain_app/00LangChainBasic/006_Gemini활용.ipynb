{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "## LangChain과 LangGraph: AI 애플리케이션 개발의 핵심 도구\n",
      "\n",
      "AI 전문가로서 LangChain과 LangGraph에 대해 설명해 드리겠습니다. 이 두 가지는 최근 AI 애플리케이션 개발 분야에서 매우 중요한 역할을 하고 있으며, 특히 **대규모 언어 모델(LLM)을 활용한 복잡한 애플리케이션을 구축하는 데 필수적인 프레임워크**입니다.\n",
      "\n",
      "### LangChain: LLM 기반 애플리케이션 구축을 위한 프레임워크\n",
      "\n",
      "**LangChain**은 LLM을 활용하여 더 강력하고 유용한 애플리케이션을 쉽게 만들 수 있도록 설계된 **오픈 소스 프레임워크**입니다. LLM 자체는 텍스트 생성, 요약, 번역 등 뛰어난 능력을 가지고 있지만, 실제 애플리케이션에서는 LLM만으로는 해결하기 어려운 문제들이 많습니다. LangChain은 이러한 문제들을 해결하기 위해 다음과 같은 핵심적인 기능들을 제공합니다.\n",
      "\n",
      "**LangChain의 주요 구성 요소 및 기능:**\n",
      "\n",
      "*   **Models (모델):** 다양한 LLM(OpenAI, Hugging Face 등)과의 연동을 지원합니다.\n",
      "*   **Prompts (프롬프트):** LLM에 전달할 입력(프롬프트)을 효과적으로 관리하고 동적으로 생성하는 기능을 제공합니다.\n",
      "*   **Chains (체인):** 여러 LLM 호출이나 다른 컴포넌트들을 순차적으로 연결하여 복잡한 작업을 수행할 수 있도록 합니다. 예를 들어, 사용자 질문을 받아 관련 문서를 검색하고, 검색된 문서를 바탕으로 LLM이 답변을 생성하는 과정을 체인으로 구성할 수 있습니다.\n",
      "*   **Indexes (인덱스):** 외부 데이터를 LLM이 이해하고 활용할 수 있도록 구조화하고 검색하는 기능을 제공합니다. 벡터 데이터베이스와의 연동이 대표적입니다.\n",
      "*   **Agents (에이전트):** LLM이 스스로 생각하고, 도구(API, 검색 엔진 등)를 사용하여 문제를 해결하도록 하는 기능입니다. LLM이 어떤 도구를 사용해야 할지 결정하고, 그 결과를 바탕으로 다음 행동을 결정하는 방식으로 작동합니다.\n",
      "*   **Memory (메모리):** 대화의 맥락을 기억하고 유지하여 LLM이 이전 대화 내용을 바탕으로 일관성 있는 응답을 생성하도록 돕습니다.\n",
      "\n",
      "**LangChain의 목표:**\n",
      "\n",
      "*   **개발 속도 향상:** LLM 기반 애플리케이션 개발에 필요한 복잡한 로직을 추상화하여 개발자가 핵심 기능에 집중할 수 있도록 합니다.\n",
      "*   **유연성 및 확장성:** 다양한 LLM, 데이터 소스, 도구와의 연동을 지원하여 애플리케이션을 유연하게 확장할 수 있습니다.\n",
      "*   **복잡한 워크플로우 구축:** 여러 단계를 거치는 복잡한 AI 작업을 쉽게 구성하고 관리할 수 있도록 합니다.\n",
      "\n",
      "### LangGraph: 상태 기반 그래프를 통한 복잡한 워크플로우 구축\n",
      "\n",
      "**LangGraph**는 LangChain의 개념을 확장하여 **상태 기반 그래프(Stateful Graph)**를 사용하여 복잡한 워크플로우를 구축하고 관리하는 데 특화된 라이브러리입니다. 특히, **반복적인 작업, 조건부 분기, 병렬 처리** 등이 필요한 동적인 AI 애플리케이션을 설계하는 데 강력한 도구입니다.\n",
      "\n",
      "**LangGraph의 핵심 개념:**\n",
      "\n",
      "*   **Graph (그래프):** 노드(Node)와 엣지(Edge)로 구성됩니다.\n",
      "    *   **Nodes (노드):** 그래프의 각 단계에서 수행되는 작업을 나타냅니다. 이는 LLM 호출, 데이터 처리, 외부 API 호출 등 다양한 형태가 될 수 있습니다.\n",
      "    *   **Edges (엣지):** 노드 간의 전환을 나타냅니다. 조건부 로직에 따라 특정 노드로 이동할 수 있습니다.\n",
      "*   **State (상태):** 그래프의 각 단계에서 공유되고 업데이트되는 데이터입니다. 이 상태는 전체 워크플로우의 맥락을 유지하는 데 사용됩니다.\n",
      "*   **Conditional Edges (조건부 엣지):** 특정 조건에 따라 다음으로 실행될 노드를 결정하는 엣지입니다. 이를 통해 분기 로직을 구현할 수 있습니다.\n",
      "*   **`add_node`, `add_edge`, `add_conditional_edges`:** 그래프를 구성하는 주요 메서드입니다.\n",
      "\n",
      "**LangGraph의 장점:**\n",
      "\n",
      "*   **복잡한 워크플로우 모델링:** 순차적인 작업뿐만 아니라, 반복, 조건부 분기, 병렬 실행 등 복잡한 로직을 직관적으로 모델링할 수 있습니다.\n",
      "*   **상태 관리 용이:** 그래프의 상태를 명확하게 정의하고 관리하여 워크플로우의 진행 상황을 추적하고 디버깅하기 쉽습니다.\n",
      "*   **재귀적 작업 구현:** 스스로를 호출하는 재귀적인 패턴을 구현하여 특정 조건이 만족될 때까지 작업을 반복할 수 있습니다.\n",
      "*   **병렬 처리:** 여러 작업을 동시에 실행하고 결과를 취합하는 등의 병렬 워크플로우를 설계할 수 있습니다.\n",
      "*   **LangChain과의 통합:** LangChain의 다양한 컴포넌트(LLM, Tools, Agents 등)를 LangGraph의 노드로 쉽게 통합하여 활용할 수 있습니다.\n",
      "\n",
      "**LangGraph의 활용 예시:**\n",
      "\n",
      "*   **복잡한 질의응답 시스템:** 사용자 질문을 분석하고, 여러 검색 엔진을 활용하며, 검색 결과를 종합하여 답변을 생성하는 과정을 그래프로 모델링할 수 있습니다.\n",
      "*   **에이전트의 다단계 추론:** 에이전트가 여러 도구를 순차적으로 사용하거나, 중간 결과에 따라 다른 도구를 선택하는 복잡한 추론 과정을 그래프로 표현할 수 있습니다.\n",
      "*   **반복적인 데이터 처리 및 분석:** 특정 조건이 만족될 때까지 데이터를 반복적으로 처리하고 분석하는 작업을 구현할 수 있습니다.\n",
      "*   **게임 AI:** 게임 내에서 캐릭터의 의사 결정 과정을 복잡한 상태 그래프로 모델링할 수 있습니다.\n",
      "\n",
      "### 요약\n",
      "\n",
      "*   **LangChain:** LLM 기반 애플리케이션 개발을 위한 **일반적인 프레임워크**로, LLM과의 연동, 프롬프트 관리, 체인 구성, 에이전트 구축 등 다양한 기능을 제공합니다.\n",
      "*   **LangGraph:** LangChain의 개념을 확장하여 **상태 기반 그래프**를 통해 복잡하고 동적인 워크플로우를 구축하는 데 특화된 라이브러리입니다. 반복, 조건부 분기, 병렬 처리 등이 필요한 경우에 특히 유용합니다.\n",
      "\n",
      "이 두 가지 도구를 함께 사용하면 LLM의 강력한 기능을 활용하여 이전에는 상상하기 어려웠던 복잡하고 지능적인 AI 애플리케이션을 효율적으로 개발할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    #model=\"gemini-2.5-pro\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    #model=\"gemini-3-pro-preview\",\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은(는) 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain과 LangGraph\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-2.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-tQs1zK9u-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
