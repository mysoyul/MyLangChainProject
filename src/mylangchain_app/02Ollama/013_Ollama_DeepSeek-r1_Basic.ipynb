{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로컬 Ollama로 설치한 deepseek-r1:1.5b 모델을 사용하기\n",
    "##### ollama run deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 deepseek-r1 모델을 로드\n",
    "llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Q: {question}\\nA:\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 질문을 입력하고 모델의 응답을 받음\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# 결과 출력\n",
    "print(type(response))\n",
    "print(response)\n",
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최신버전 LangChain에서는 ChatOllama와 RunnableSequence(prompt | llm) 를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KOSTA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-tQs1zK9u-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='Python (pronounced:\\u202fPAh-n ahn) is a high-level programming language that is widely used for various applications such as software development, data analysis, machine learning, and web development. It was created by Guido van Rosbroek and Tom Van Roy from the Technical University of Eindhoven in 1985 and has been continuously maintained since then.\\n\\nPython\\'s name comes from \"Pascal\" after one of his famous ideas related to the language. The name is also transliterated as \"Pan\" by French programmers. However, the core features and syntax have evolved over time, so it\\'s important to refer to the current official names and implementations for the latest information.\\n\\nSome key features of Python include:\\n\\n1. **High-level language**: Python is an object-oriented programming language that allows developers to write code in a concise and readable manner.\\n2. **Dynamic typing**: Unlike some other languages (e.g., C, Java), Python automatically determines data types during runtime.\\n3. **Widely supported libraries and frameworks**: Python has a vast ecosystem of third-party packages for various domains, making it easier to work with specialized tasks like web development, natural language processing, and more.\\n4. **Interactive development environment (IDEs)**: Many users find Python\\'s interactive nature through IDEs like Jupyter Notebook or CodePen extremely user-friendly.\\n\\nPython is also known as \"scilab\" in some European languages, reflecting its extensive collection of scientific computing tools. However, Python remains the most popular choice for general programming and its versatility make it a fundamental tool for anyone working with software development.' additional_kwargs={} response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-12-09T03:18:04.357031Z', 'done': True, 'done_reason': 'stop', 'total_duration': 68926009600, 'load_duration': 167301500, 'prompt_eval_count': 24, 'prompt_eval_duration': 630895200, 'eval_count': 407, 'eval_duration': 65957074200, 'logprobs': None, 'model_name': 'deepseek-r1:1.5b'} id='run--97514050-554f-4833-95ca-33f8d2e1afda-0' usage_metadata={'input_tokens': 24, 'output_tokens': 407, 'total_tokens': 431}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "# prompt_template = PromptTemplate.from_template(\"Q: {question}\\nA:\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is Pyhon?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python (pronounced: PAh-n ahn) is a high-level programming language that is widely used for various applications such as software development, data analysis, machine learning, and web development. It was created by Guido van Rosbroek and Tom Van Roy from the Technical University of Eindhoven in 1985 and has been continuously maintained since then.\n",
      "\n",
      "Python's name comes from \"Pascal\" after one of his famous ideas related to the language. The name is also transliterated as \"Pan\" by French programmers. However, the core features and syntax have evolved over time, so it's important to refer to the current official names and implementations for the latest information.\n",
      "\n",
      "Some key features of Python include:\n",
      "\n",
      "1. **High-level language**: Python is an object-oriented programming language that allows developers to write code in a concise and readable manner.\n",
      "2. **Dynamic typing**: Unlike some other languages (e.g., C, Java), Python automatically determines data types during runtime.\n",
      "3. **Widely supported libraries and frameworks**: Python has a vast ecosystem of third-party packages for various domains, making it easier to work with specialized tasks like web development, natural language processing, and more.\n",
      "4. **Interactive development environment (IDEs)**: Many users find Python's interactive nature through IDEs like Jupyter Notebook or CodePen extremely user-friendly.\n",
      "\n",
      "Python is also known as \"scilab\" in some European languages, reflecting its extensive collection of scientific computing tools. However, Python remains the most popular choice for general programming and its versatility make it a fundamental tool for anyone working with software development.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 (Pascal)은 영국의 컴퓨터 학자이자 수학자가 개발한 프로그래밍 언어입니다.\n",
      "\n",
      "해당 질문에서 사용된 \"파이썬\"은 과학적 용어로 \"바나프스\" (Babbage)를 의미합니다. 이는 런던 대학교에서 귀속을 한 프로그래밍 언어의 첫 번째 버전으로, 1960년대에 만들어진 것입니다.\n",
      "\n",
      "파이썬은 일반적인 Python이라는 이름에서도 비유적 개념입니다. 초기에는 '산다', '바나프스'라는 의미였는데, 이는 그 당시 프로그래밍 언어들이 빈약하고 난해하기 때문에, 파이썬을 통해 쉽게 배울 수 있다는 의미가 담겨 있었습니다.\n",
      "\n",
      "파이썬은 복잡한 구조를 쉽게 이해하고 기능적으로 간단하게 사용할 수 있도록 설계되었습니다. 이로 인해 앱 개발자들에게 매우 유용하게 작동하여, 현재까지도 주요 프로그래밍 언어 중 하나로 자리 잡고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-tQs1zK9u-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
